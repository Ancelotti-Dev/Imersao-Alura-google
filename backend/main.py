import os
from datetime import date
from dotenv import load_dotenv
import google.generativeai as genai
from google.adk.agents import Agent
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.genai import types

# Carregar chave
load_dotenv(dotenv_path='backend/chave.env')
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# Modelo padrÃ£o
model = genai.GenerativeModel('gemini-2.0-flash')

# ConfiguraÃ§Ãµes de seguranÃ§a (opcional)
safety_settings = [
    {"category": "HARM_CATEGORY_DEROGATORY", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    {"category": "HARM_CATEGORY_VIOLENCE", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    {"category": "HARM_CATEGORY_SEXUAL", "threshold": "BLOCK_HIGH_AND_ABOVE"},
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"}
]

# --- FunÃ§Ã£o genÃ©rica para gerar resposta com modelo --- #
def gerar_resposta(prompt, model_name='gemini-2.0-flash'):
    model = genai.GenerativeModel(model_name)
    response = model.generate_content(prompt)
    return response.text

# --- ExecuÃ§Ã£o de agente com estado --- #
def call_agent(agent: Agent, message_text: str) -> str:
    session_service = InMemorySessionService()
    session = session_service.create_session(app_name=agent.name, user_id="user1", session_id="session1")
    runner = Runner(agent=agent, app_name=agent.name, session_service=session_service)
    content = types.Content(role="user", parts=[types.Part(text=message_text)])

    final_response = ""
    for event in runner.run(user_id="user1", session_id="session1", new_message=content):
        if event.is_final_response():
            for part in event.content.parts:
                if part.text:
                    final_response += part.text + "\n"
    return final_response

# --- FunÃ§Ãµes dos agentes --- #
def mentor_futuro(vocacao, data_de_hoje):
    prompt = f"""
    VocÃª Ã© um mentor de carreira com 20 anos de experiÃªncia em tendÃªncias profissionais.
    Hoje Ã© {data_de_hoje}. O usuÃ¡rio descreveu sua vocaÃ§Ã£o e interesses assim: "{vocacao}".
    
    FaÃ§a 2 a 3 perguntas abertas para entender melhor o perfil do usuÃ¡rio e, com base nisso,
    recomende 1 ou 2 profissÃµes do futuro que combinem com esse perfil.

    Deixe tudo separadinho bonito, quero nada junto, para cada topico pula uma linha e coloque em negrito todas palavras importes

    Finalize perguntando se o usuÃ¡rio gostaria de receber uma sugestÃ£o de curso.
    """
    return gerar_resposta(prompt)

def curador_cursos(profissao, contexto_anterior):
    prompt = f"""
    Baseado neste contexto: {contexto_anterior}

    VocÃª Ã© um curador de trilhas de aprendizado.
    Sugira 3 cursos (iniciante, intermediÃ¡rio e avanÃ§ado) para a profissÃ£o '{profissao}'.
    Deixe tudo separadinho bonito, quero nada junto, para cada topico pula uma linha e coloque em negrito todas palavras importes
    VocÃª Ã© um especialista e vendedor dos cursos da Alura ou gratuitos de alta qualidade. Descreva cada curso de forma atrativa e clara.
    """
    return gerar_resposta(prompt)

def psicologo_perfil(contexto_anterior):
    prompt = f"""
    Com base neste histÃ³rico de conversa: {contexto_anterior}

    VocÃª Ã© um especialista em perfil vocacional.
    Deixe tudo separadinho bonito, quero nada junto, para cada topico pula uma linha e coloque em negrito todas palavras importes
    FaÃ§a uma anÃ¡lise comportamental destacando traÃ§os como: criativo, analÃ­tico, executor, empÃ¡tico.
    Seja acolhedor, empÃ¡tico e profissional.
    """
    return gerar_resposta(prompt)

def radar_profissional(profissao, contexto_anterior):
    prompt = f"""
    ProfissÃ£o: '{profissao}'
    HistÃ³rico: {contexto_anterior}
    Deixe tudo separadinho bonito, quero nada junto, para cada topico pula uma linha e coloque em negrito todas palavras importes
    Apresente dados atualizados de mercado:
    - SalÃ¡rio mÃ©dio
    - Ãreas com mais contrataÃ§Ãµes
    - Remoto ou presencial
    - RegiÃµes com maior demanda

    Seja claro e objetivo.
    """
    return gerar_resposta(prompt)

def coach_trajetoria(profissao, contexto_anterior):
    prompt = f"""
    UsuÃ¡rio deseja seguir carreira em '{profissao}'. Contexto: {contexto_anterior}

    Crie um plano com 3 a 5 etapas prÃ¡ticas:
    - Habilidade essencial para desenvolver
    - Como criar portfÃ³lio/currÃ­culo
    - Dicas de networking
    - Etapas para estÃ¡gio ou primeiro emprego
    Deixe tudo separadinho bonito, quero nada junto, para cada topico pula uma linha e coloque em negrito todas palavras importes
    Seja inspirador e direto.
    """
    return gerar_resposta(prompt)

# ğŸ” Fluxo da Mentoria com vocaÃ§Ã£o primeiro
def mentoria_completa_encadeada(vocacao):
    data_hoje = date.today().strftime("%d/%m/%Y")
    print("ğŸš€ Iniciando mentoria com IA...\n")

    etapa1 = mentor_futuro(vocacao, data_hoje)
    print("\nğŸ§­ Mentor Futuro:\n", etapa1)

    # Suponha que o modelo retorne as profissÃµes sugeridas na etapa1
    # Vamos extrair uma profissÃ£o de exemplo para seguir o fluxo (em produÃ§Ã£o use NLP para extrair com precisÃ£o)
    profissao = input("\nğŸ’¼ Com base nisso, digite uma das profissÃµes sugeridas que te interessou: ").strip()

    if not profissao:
        print("âš ï¸ Nenhuma profissÃ£o informada, encerrando.")
        return

    etapa2 = curador_cursos(profissao, etapa1)
    print("\nğŸ“˜ Curador de Cursos:\n", etapa2)

    etapa3 = psicologo_perfil(etapa1 + etapa2)
    print("\nğŸ§  PsicÃ³logo de Perfil:\n", etapa3)

    etapa4 = radar_profissional(profissao, etapa1 + etapa2 + etapa3)
    print("\nğŸ“Š Radar Profissional:\n", etapa4)

    etapa5 = coach_trajetoria(profissao, etapa1 + etapa2 + etapa3 + etapa4)
    print("\nğŸ¯ Coach de TrajetÃ³ria:\n", etapa5)

# ğŸ¯ Roda o sistema
if __name__ == "__main__":
    print("ğŸ§  Bem-vindo Ã  Mentoria de Carreira com IA")
    vocacao = input("Descreva brevemente sua vocaÃ§Ã£o, talentos ou paixÃµes: ").strip()

    if not vocacao:
        print("âš ï¸ Nenhuma vocaÃ§Ã£o informada!")
    else:
        mentoria_completa_encadeada(vocacao)
